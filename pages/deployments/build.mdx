# Build and Push

Before you create the [**inference project**](../concepts/project), you need to first build it and push to a Docker registry. 

The inference server is a Docker image that contains the prediction code and all the dependencies.

## Build

We recommend using our CLI `modelz` to build the inference server. 

WIP.

