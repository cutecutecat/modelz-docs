# Build and Push

Before you create the [**inference project**](../concepts/project), you need to first build and push the [**inference server**](../concepts/server) to a Docker registry. 

The inference server is a Docker image that contains the prediction code and all the dependencies.

## Build

We recommend using our CLI `modelz` to build the inference server. 

WIP.

